# Example secrets for local development. See docs/INANNA_CORE.md for details.
# When running on a Vast.ai server the repository usually resides under
# `/workspace/THESPIRAL`. Recommended service ports are:
#   8000 - FastAPI interface
#   8001 - GLM service
#   8002 - DeepSeek servant
#   8003 - Mistral servant
#   8010 - Kimi-K2 servant
# Model weights can be placed under `/workspace/THESPIRAL/INANNA_AI/models`.
HF_TOKEN=hf_dummy_token
GITHUB_TOKEN=
OPENAI_API_KEY=
GLM_API_URL=http://localhost:8001  # use http://<ip>:8001 on Vast.ai
GLM_API_KEY=dummy-token
GLM_SHELL_URL=  # e.g. http://<ip>:8011
GLM_SHELL_KEY=
GLM_COMMAND_TOKEN=
REFLECTION_INTERVAL=
CORPUS_PATH=
QNL_EMBED_MODEL=all-MiniLM-L6-v2
QNL_MODEL_PATH=  # e.g. /workspace/THESPIRAL/INANNA_AI/models/qnl
EMBED_MODEL_PATH=  # e.g. /workspace/THESPIRAL/INANNA_AI/models/embedder
VOICE_TONE_PATH=  # e.g. /workspace/THESPIRAL/data/voice_tones
VECTOR_DB_PATH=
RETRAIN_THRESHOLD=
VOICE_CONFIG_PATH=
EMOTION_STATE_PATH=
DEEPSEEK_URL=  # e.g. http://<ip>:8002
MISTRAL_URL=   # e.g. http://<ip>:8003
KIMI_K2_URL=  # e.g. http://<ip>:8010
LLM_ROTATION_PERIOD=300
LLM_MAX_FAILURES=3
ARCHETYPE_STATE=ALBEDO
